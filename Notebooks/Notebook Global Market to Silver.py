#!/usr/bin/env python
# coding: utf-8

# ## Notebook Global Market to Silver
# 
# New notebook

# In[1]:


# Welcome to your new notebook
# Type here in the cell editor to add code!

# Step 1: Read from Brone Lakehouse using Spark SQL or OneLake shortcut

df_global_bronze = spark.read.format("delta").load("abfss://dd18648f-6099-472b-9cc8-e045d09f8f4b@onelake.dfs.fabric.microsoft.com/2ba89c3a-f525-4ba0-8bc3-4b150edc193b/Tables/global_market")


#  Step 2 :Data transformation 


# In[ ]:


# Code generated by Data Wrangler for PySpark DataFrame

from pyspark.ml.feature import Imputer

def clean_data(df_global_bronze):
    # Replace missing values with "" in columns: 'Region', 'Segment', 'Distribution_Channel'
    df_global_bronze = df_global_bronze.fillna(value="", subset=['Region', 'Segment', 'Distribution_Channel'])
    # Replace missing values with the mean of each column in: 'Demand_Growth_%', 'Supply_Chain_Index' and 3 other columns
    cols = ['Demand_Growth_%', 'Supply_Chain_Index', 'Trade_Tariff_Impact_%', 'Health_Trend_Index', 'Market_Size_USD_Billion']
    imputer = Imputer(inputCols=cols, outputCols=cols, strategy='mean')
    df_global_bronze = imputer.fit(df_global_bronze).transform(df_global_bronze)
    return df_global_bronze

df_global_bronze_clean = clean_data(df_global_bronze)
display(df_global_bronze_clean)


# In[ ]:


# Step 3: Save cleaned data into Silver layer 
df_global_bronze_clean.write.mode("overwrite").format("delta").save("Tables/global_market_silver")

